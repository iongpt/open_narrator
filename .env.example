# Application Settings
APP_NAME=OpenNarrator
DEBUG=false
LOG_LEVEL=INFO
# Silence SQLAlchemy logs (except errors) - reduces log noise
SILENCE_SQLALCHEMY=true

# Database
DATABASE_URL=sqlite:///./data/app.db

# File Storage
UPLOAD_DIR=./data/uploads
OUTPUT_DIR=./data/outputs
MODEL_DIR=./data/models
DEBUG_DIR=./data/debug
MAX_UPLOAD_SIZE_MB=50
BULK_INPUT_DIR=./data/bulk/input
BULK_OUTPUT_DIR=./data/bulk/output
BULK_PRESET_PATH=./data/bulk/preset.json
BULK_SCAN_INTERVAL_SECONDS=60

# Job Dispatcher
MAX_CONCURRENT_JOBS=1
DISPATCHER_POLL_INTERVAL_SECONDS=1.0

# AI Services
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Whisper Settings (auto-detected: cuda or cpu)
# Model Selection Guide (CPU performance on M1 Mac for 10MB file):
#   tiny    - ~75MB,  ~30s,  decent quality (good for testing)
#   base    - ~145MB, ~1min, good quality (recommended for development)
#   small   - ~466MB, ~3min, very good quality
#   medium  - ~1.5GB, ~8min, excellent quality (recommended for production)
#   large-v2/v3 - ~3GB, ~15min, best quality (only if accuracy is critical)
#
# For fast testing: use 'base'
# For production: use 'medium' or 'large-v3'
WHISPER_MODEL=base
# Compute type for GPU: float16, int8_float16
# Compute type for CPU: int8, int8_float32
WHISPER_COMPUTE_TYPE=auto
# Voice Activity Detection - filters silence but can cause audio truncation
# Set to false if experiencing incomplete transcriptions
WHISPER_VAD_FILTER=false

# Translation Settings
TRANSLATION_MODEL=claude-sonnet-4-5-20250929
# Maximum tokens per chunk (input text) - chunks have no overlap
TRANSLATION_MAX_TOKENS=20000
# Maximum output tokens from LLM
TRANSLATION_MAX_OUTPUT_TOKENS=64000

# TTS Settings
TTS_ENGINE=piper
# Piper voice models will be downloaded on first use

# Server Settings
HOST=0.0.0.0
PORT=8000
WORKERS=1
